{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = [ 28.44,  29.32,  31.22,  29.58,  30.34,  28.76,  29.21,  30.4 ,\n",
    "              31.12,  31.78,  27.58,  31.57,  30.73,  30.43,  30.31,  30.32,\n",
    "              29.18,  29.52,  29.22,  30.56]\n",
    "control = [ 33.51,  30.63,  32.38,  32.52,  29.41,  30.93,  49.78,  28.96,\n",
    "            35.77,  31.42,  30.76,  30.6 ,  23.64,  30.54,  47.78,  31.98,\n",
    "            34.52,  32.42,  31.32,  40.72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nottest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ffafe170951b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# decorator to prevent nose to consider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this as a unit test due to \"test\" in the name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mnottest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m def permutation_test(x, y, func='x_mean != y_mean', method='exact',\n\u001b[1;32m      5\u001b[0m                      num_rounds=1000, seed=None):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nottest' is not defined"
     ]
    }
   ],
   "source": [
    "# decorator to prevent nose to consider\n",
    "# this as a unit test due to \"test\" in the name\n",
    "@nottest\n",
    "def permutation_test(x, y, func='x_mean != y_mean', method='exact',\n",
    "                     num_rounds=1000, seed=None):\n",
    "    \"\"\"\n",
    "    Nonparametric permutation test\n",
    "    Parameters\n",
    "    -------------\n",
    "    x : list or numpy array with shape (n_datapoints,)\n",
    "        A list or 1D numpy array of the first sample\n",
    "        (e.g., the treatment group).\n",
    "    y : list or numpy array with shape (n_datapoints,)\n",
    "        A list or 1D numpy array of the second sample\n",
    "        (e.g., the control group).\n",
    "    func : custom function or str (default: 'x_mean != y_mean')\n",
    "        function to compute the statistic for the permutation test.\n",
    "        - If 'x_mean != y_mean', uses\n",
    "          `func=lambda x, y: np.abs(np.mean(x) - np.mean(y)))`\n",
    "           for a two-sided test.\n",
    "        - If 'x_mean > y_mean', uses\n",
    "          `func=lambda x, y: np.mean(x) - np.mean(y))`\n",
    "           for a one-sided test.\n",
    "        - If 'x_mean < y_mean', uses\n",
    "          `func=lambda x, y: np.mean(y) - np.mean(x))`\n",
    "           for a one-sided test.\n",
    "    method : 'approximate' or 'exact' (default: 'exact')\n",
    "        If 'exact' (default), all possible permutations are considered.\n",
    "        If 'approximate' the number of drawn samples is\n",
    "        given by `num_rounds`.\n",
    "        Note that 'exact' is typically not feasible unless the dataset\n",
    "        size is relatively small.\n",
    "    num_rounds : int (default: 1000)\n",
    "        The number of permutation samples if `method='approximate'`.\n",
    "    seed : int or None (default: None)\n",
    "        The random seed for generating permutation samples if\n",
    "        `method='approximate'`.\n",
    "    Returns\n",
    "    ----------\n",
    "    p-value under the null hypothesis\n",
    "    Examples\n",
    "    -----------\n",
    "    For usage examples, please see\n",
    "    http://rasbt.github.io/mlxtend/user_guide/evaluate/permutation_test/\n",
    "    \"\"\"\n",
    "\n",
    "    if method not in ('approximate', 'exact'):\n",
    "        raise AttributeError('method must be \"approximate\"'\n",
    "                             ' or \"exact\", got %s' % method)\n",
    "\n",
    "    if isinstance(func, str):\n",
    "\n",
    "        if func not in (\n",
    "                'x_mean != y_mean', 'x_mean > y_mean', 'x_mean < y_mean'):\n",
    "            raise AttributeError('Provide a custom function'\n",
    "                                 ' lambda x,y: ... or a string'\n",
    "                                 ' in (\"x_mean != y_mean\", '\n",
    "                                 '\"x_mean > y_mean\", \"x_mean < y_mean\")')\n",
    "\n",
    "        elif func == 'x_mean != y_mean':\n",
    "            def func(x, y):\n",
    "                return np.abs(np.mean(x) - np.mean(y))\n",
    "\n",
    "        elif func == 'x_mean > y_mean':\n",
    "            def func(x, y):\n",
    "                return np.mean(x) - np.mean(y)\n",
    "\n",
    "        else:\n",
    "            def func(x, y):\n",
    "                return np.mean(y) - np.mean(x)\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    m, n = len(x), len(y)\n",
    "    combined = np.hstack((x, y))\n",
    "\n",
    "    more_extreme = 0.\n",
    "    reference_stat = func(x, y)\n",
    "\n",
    "    # Note that whether we compute the combinations or permutations\n",
    "    # does not affect the results, since the number of permutations\n",
    "    # n_A specific objects in A and n_B specific objects in B is the\n",
    "    # same for all combinations in x_1, ... x_{n_A} and\n",
    "    # x_{n_{A+1}}, ... x_{n_A + n_B}\n",
    "    # In other words, for any given number of combinations, we get\n",
    "    # n_A! x n_B! times as many permutations; hoewever, the computed\n",
    "    # value of those permutations that are merely re-arranged combinations\n",
    "    # does not change. Hence, the result, since we divide by the number of\n",
    "    # combinations or permutations is the same, the permutations simply have\n",
    "    # \"n_A! x n_B!\" as a scaling factor in the numerator and denominator\n",
    "    # and using combinations instead of permutations simply saves computational\n",
    "    # time\n",
    "\n",
    "    if method == 'exact':\n",
    "        for indices_x in combinations(range(m + n), m):\n",
    "\n",
    "            indices_y = [i for i in range(m + n) if i not in indices_x]\n",
    "            diff = func(combined[list(indices_x)], combined[indices_y])\n",
    "\n",
    "            if diff > reference_stat:\n",
    "                more_extreme += 1.\n",
    "\n",
    "        num_rounds = factorial(m + n) / (factorial(m)*factorial(n))\n",
    "\n",
    "    else:\n",
    "        for i in range(num_rounds):\n",
    "            rng.shuffle(combined)\n",
    "            if func(combined[:m], combined[m:]) > reference_stat:\n",
    "                more_extreme += 1.\n",
    "\n",
    "    return more_extreme / num_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0066\n"
     ]
    }
   ],
   "source": [
    "p_value = permutation_test(treatment, control,\n",
    "                           method='approximate',\n",
    "                           num_rounds=10000,\n",
    "                           seed=0)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[233, 213], [115, 120]]\n",
      "dof=1\n",
      "[[227.91189427 218.08810573]\n",
      " [120.08810573 114.91189427]]\n",
      "probability=0.950, critical=3.841, stat=0.547\n",
      "Independent (fail to reject H0)\n",
      "significance=0.050, p=0.459\n",
      "Independent (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# chi-squared test with similar proportions\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "# contingency table\n",
    "table = [\t[233,213],\n",
    "\t\t\t[115,120]]\n",
    "print(table)\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "if abs(stat) >= critical:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5385686353206903\n",
      "0.9148865899093268\n",
      "0.8826276321870212\n",
      "0.7469384431180537\n",
      "0.851451073607717\n",
      "0.26256775894801165\n",
      "0.7453304818766431\n",
      "0.39470746096305553\n",
      "0.17506429887055489\n",
      "0.19755431393631664\n",
      "0.8772919683599982\n",
      "0.393042166709098\n",
      "0.03255257987745147 *** \"significant\"\n",
      "0.2318154263650974\n",
      "0.3933537408586837\n",
      "0.24732681560032269\n",
      "0.603492904494551\n",
      "0.5729713922708124\n",
      "0.6576651236826774\n",
      "0.29677074191083047\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def run_experiment(n: int) -> float:\n",
    "    x = np.random.normal(0, 1, n)\n",
    "    y = np.random.normal(0, 1, n)\n",
    "    ttest = stats.ttest_ind(x, y)\n",
    "    return ttest.pvalue\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "experiments = 20\n",
    "n = 100\n",
    "\n",
    "for i in range(experiments):\n",
    "    p = run_experiment(n)\n",
    "    if p < alpha/experiments:\n",
    "        print(p, '!!! \"significant with Bonferroni correction\"')\n",
    "    elif p < alpha:\n",
    "        print(p, '*** \"significant\"')\n",
    "    else:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
